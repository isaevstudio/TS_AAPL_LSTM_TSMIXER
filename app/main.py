import warnings

from dotenv import load_dotenv
import mlflow
import pandas as pd
import numpy as np
from model.train import build_model, train_model, tune_hyperparameters
from preprocessing.prepare_data import df_date_convert, from_csv_summarize, from_csv_sentiment
from utils.utils import prepare_data, predict_and_evaluate, metrics, plot_predictions_LSTM

from keras.models import Sequential

from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam, RMSprop


import os

warnings.filterwarnings('ignore')
load_dotenv()


# params
RANDOM_STATE = os.getenv["RANDOM_STATE"]
raw_news_path = os.getenv["raw_news_path"]
raw_price_path = os.getenv["raw_price_path"]

ready_for_pred = os.getenv["ready_for_pred"]

# Data used for finetuning the sentiment model (generated by ChatGPT-4o)
synthetic_data_finetune = os.getenv["synthetic_data_finetune"]

# For our optuna
configs = os.getenv["configs"]




if __name__ == "__main__":

# ------------------------------------ Data prep!
    # Too slove on local machine. For the full data please refere to colab.
    # In the following app I have divided them into seperate folders for easy usage

    """    
    # Converting the datetime
    news_saving_path = '../dataset/news_data_preprocessed'
    stock_saving_path = './dataset/stock_price_data_preprocessed'

    try:
        df_date_convert(raw_news_path, news_saving_path)
        df_date_convert(raw_price_path, stock_saving_path)
    except:
        os.makedirs(news_saving_path, exist_ok=True)
        os.makedirs(stock_saving_path, exist_ok=True)

        df_date_convert(raw_news_path, news_saving_path)
        df_date_convert(raw_price_path, stock_saving_path)

    # Summarizing the news
    news_read_path = "../dataset/news_data_preprocessed"
    news_saving_path = "../dataset/news_data_summarized"

    try:
        from_csv_summarize(news_read_path, news_saving_path)
    except:
        os.makedirs(news_saving_path, exist_ok=True)
        from_csv_summarize(news_read_path, news_saving_path)

    # Sentiment
    news_read_path = "../dataset/news_data_summarized"
    news_saving_path = '../dataset/news_data_summarized_sentiment'

    try:
        from_csv_sentiment(news_read_path, news_saving_path)

    except:
        os.makedirs(news_saving_path, exist_ok=True)

        from_csv_sentiment(news_read_path, news_saving_path)
    """



# ------------------------------------ Data predict + hypertune
    EXPERIMENT_NAME = 'first_experiment'
    mlflow.set_tracking_uri("http://127.0.0.1:5000")
    mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)

    with mlflow.start_run():

        df = pd.read_csv(ready_for_pred)
        df = df[['open', 'high', 'low', 'close', 'adj close', 'volume', 'scaled_sentiment']]
        df = df.dropna()

        best_params = tune_hyperparameters()
        mlflow.log_params(best_params)

        x_train, y_train, x_test, y_test, scaler = prepare_data(df, best_params['sequence_length'], target_column='close')

        dataset = mlflow.data.from_pandas(x_train)
        mlflow.log_input(dataset, context='logging the AAPL dataset')

        # Prepare data
        model = Sequential()
        model.add(LSTM(best_params['neurons_lstm'], activation='tanh', input_shape=(best_params['sequence_length'], x_train.shape[2]), return_sequences=False))
        model.add(Dropout(best_params['dropout_rate']))
        model.add(Dense(1, activation='linear'))

        optimizer = Adam(learning_rate=best_params['learning_rate']) if best_params['optimizer'] == 'adam' else RMSprop(learning_rate=best_params['learning_rate'])
        model.compile(optimizer=optimizer, loss='mse')

        model.fit(
            x_train,
            y_train,
            validation_split=0.1,
            epochs=20,
            batch_size=best_params['batch_size'],
            callbacks=[EarlyStopping(monitor='val_loss', patience=2, verbose=1)],
            verbose=1
        )

        input_example = x_test.sample(5)
        mlflow.keras.log_model(model, "model_LSTM", input_example=input_example)


        # Build, Train, and Predict
        predictions = model.predict(x_test)
        predictions = scaler.inverse_transform(np.concatenate([np.zeros((predictions.shape[0], df.shape[1] - 1)), predictions], axis=1))[:, -1]
        y_test = scaler.inverse_transform(np.concatenate([np.zeros((y_test.shape[0], df.shape[1] - 1)), y_test.reshape(-1, 1)], axis=1))[:, -1]

        # Evaluation
        results_eval = metrics(test=y_test, prediction=predictions)
        print(results_eval)

        mse_score = results_eval.loc[results_eval['eval'] == 'MSE', 'score'].values[0]
        mlflow.log_metric("MSE", mse_score)

        mae_score = results_eval.loc[results_eval['eval'] == 'MAE', 'score'].values[0]
        mlflow.log_metric("MAE", mae_score)

        r2_score = results_eval.loc[results_eval['eval'] == 'R2', 'score'].values[0]
        mlflow.log_metric("R2", r2_score)
        

        # Plot predictions
        fig = plot_predictions_LSTM(y_test, predictions)
        mlflow.log_figure(fig, "lSTM.png")